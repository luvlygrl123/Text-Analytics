ARF <- arima(AMZN$close)
plot(ARF)
acf(diff(AMZN$cl))
acf(diff(AMZN$close))
a <- arima.sim(model = list(c(1,0,0),ar = 0.8),n = 100)
b <- arima.sim(model = list(c(1,0,0),ar=0.95),n = 100)
plot.ts(cbind(a,b))
#simulate an AR model with .8 slope
a <- arima.sim(model = list(c(1,0,0),ar = 0.8),n = 100)
#.95 slope
b <- arima.sim(model = list(c(1,0,0),ar = 0.95),n = 100)
plot.ts(cbind(a,b))
b <- arima.sim(model = list(c(1,0,0),ar = -0.95),n = 100)
plot.ts(cbind(a,b))
library(Ecdat)
install.packages("Ecdat")
library(Ecdat)
data(Mishkin)
monthly_inflation <- as.ts(Mishkin[,1])
ts.plot(monthly_inflation
)
ts.plot(monthly_inflation)
acf(monthly_inflation)
ar_mon_inf <- arima(monthly_inflation, order=c(1,0,0))
print(ar_mon_inf)
ts.plot(monthly_inflation)
ar_mon_inf_fit <- monthly_inflation-residuals(ar_mon_inf)
points(ar_mon_inf_fit, type="1", col="#125436", lty=3)
# installing/loading the package:
if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr
# step by step functions:
check.for.updates.R() # tells you if there is a new version of R or not.
install.R() # download and run the latest R installer
copy.packages.between.libraries() # copy your packages to the newest R installation from the one version before it (if ask=T, it will ask you between which two versions to perform the copying)
points(ar_mon_inf_fit, type="l", col="#125436", lty=3)
predict(ar_mon_inf,10)
BAC <- tq_get("BAC", get = "stock.prices", from = "2016-12-01", to = "2017-09-01")
plot.ts(AMZN$close)
plot.ts(BAC$close)
Xtb <- BAC$close[-1]
Xt_1b <- BAC$close[-length(BAC$close)]
cor(Xtb,Xt_1b)
cor(BAC$close[-(1:2)],BAC$close[-(250:251)])
acf(BAC$close)
BAC_price_model <- arima(BAC$close, order=c(1,0,0))
print(BAC_price_model)
ts.plot(BAC$close)
BAC_P_fit <- BAC$close-residuals(BAC_price_model)
points(BAC_P_fit,type="l", col="#6644ff")
points(BAC_P_fit,type="l", col="#6644ff", lty=3)
points(BAC_P_fit,type="l", col="#2244aa", lty=3)
points(BAC_P_fit,type="l", col="#9944aa", lty=3)
points(BAC_P_fit,type="l", col="#99ppaa", lty=3)
points(BAC_P_fit,type="l", col="#9999aa", lty=3)
points(BAC_P_fit,type="l", col="#9999ff", lty=3)
points(BAC_P_fit,type="l", col="#aaaaff", lty=3)
ts.plot(BAC$close)
BAC_for <- predict(BAC_price_model, n.ahead = 15)$pred
BAC_fSE <- predict(BAC_price_model, n.ahead = 15)$se
points(BAC_for, type="l", col = "#66ffaa")
points(BAC_for - 2*BAC_fSE, type="l", col = "#ff66aa")
points(BAC_for + 2*BAC_fSE, type="l", col = "#aa66ff")
points(BAC_for - 2*BAC_fSE, type="l", col = "#ff66aa", lty = 2)
points(BAC_for + 2*BAC_fSE, type="l", col = "#aa66ff", lty = 2)
a <- arima.sim(model = list(c(0,0,1), ma = 0.8), n = 100)
b <- arima.sim(model = list(c(0,0,1), ma = -0.5), n = 100)
plot.ts(cbind(a,b))
a <- arima.sim(model = list(c(0,0,1), ma = 0.8), n = 100)
b <- arima.sim(model = list(c(0,0,1), ma = -0.5), n = 100)
plot.ts(cbind(a,b))
aa <- acf(a)
bb <- acf(b)
plot.ts(cbind(aa,bb))
plot(cbind(aa,bb))
mon_inf <- as.ts(Mishkin[,1])
mon_i_ch <- diff(mon_inf)
ts.plot(mon_i_ch)
acf(mon_i_ch)
MA_mon_inf <- arima(mon_i_ch, order=c(0,0,1))
print(MA_mon_inf)
ts.plot(mon_i_ch)
MA_mon_ch <-mon_i_ch-residuals(MA_mon_ch)
MA_mon_chf <-mon_i_ch-residuals(mon_i_ch)
points(MA_mon_chf)
points(MA_mon_chf, type="l", col="#ff5566")
points(MA_mon_chf, type="l", col="#ff5566", ity=3)
MA_mon_chf <-mon_i_ch-residuals(mon_i_ch)
points(MA_mon_chf, type="l", col="#ff5566", ity=3)
MA_mon_chf <-mon_i_ch-residuals(MA_mon_if)
MA_mon_chf <-mon_i_ch-residuals(MA_mon_inf)
points(MA_mon_chf, type="l", col="#ff5566", ity=3)
points(MA_mon_chf, type="l", col="#ff5566", lty=3)
ts.plot(mon_i_ch)
MA_mon_chf <-mon_i_ch-residuals(MA_mon_inf)
points(MA_mon_chf, type="l", col="#ff5566", lty=3)
predict(MA_mon_chf,10)
a <- arima.sim(model = list(c(1,0,1),ar = 2.3, ma = 1.4), n = 1000)
b <- arima.sim(model = list(c(1,0,1),ar = 1.4, ma = 2.3), n = 1000)
a <- arima.sim(model = list(c(1,0,1),ar = 1.2, ma = 1.4), n = 1000)
a <- arima.sim(model = list(c(1,0,1),ar = 0.9, ma = 1.4), n = 1000)
b <- arima.sim(model = list(c(1,0,1),ar = 0.9, ma = 2.3), n = 1000)
plot.ts(cbind(a,b))
dataset(rec)
libray(astsa)
plot.ts(rec)
library(astsa)
plot.ts(rec)
library(tseries)
plot.ts(rec)
adf.test(tsData)
adf.test(rec)
acf(rec)
pacf(rec)
fit1 <- sarima(rec, p=1, q=0, d=0)
fit2 <- sarima(rec, p=2, q=0, d=0)
a <- arima.sim(model = list(c(1,0,0),ar=0.8), n = 100)
b <- arima.sim(model = list(c(1,0,0),ar=-0.95), n = 100)
library(astsa)
library(tseries)
data(rec)
plot.ts(rec)
adf.test(rec)
acf2(rec)
fit_1 <- sarima(rec,p=1,q=0,d=0)
fit_2 <- sarima(rec,p=2,q=0,d=0)
fit_3 <- sarima(rec,p=1,q=0,d=1)
fit_4 <- sarima(rec,p=3,q=0,d=0)
fit_2$ttable
sarima.for(rec,n.ahead=10,p=2,q=0,d=0)
library(astsa)
x<- arima.sim(model = list(order = c(2,0,0), ar = c(1.25,-0.75)), n = 200) + 25
library(astsa)
x<- arima.sim(model = list(order = c(2,0,0), ar = c(1.25,-0.75)), n = 200) + 25
plot.ts(x)
library(tseries)
adf.test(x)
library(isdals)
data(bodyfat)
install.packages(isdals)
library(isdals)
data(bodyfat)
install.packages("isdals")
library(isdals)
data(bodyfat)
fit_1 <- sarima(rec,p=1,q=0,d=0)
fit_2 <- sarima(rec,p=2,q=0,d=0)
fit_3 <- sarima(rec,p=1,q=0,d=1)
fit_4 <- sarima(rec,p=3,q=0,d=0)
x<- arima.sim(model = list(order = c(2,0,0), ar = c(1.25,-0.75)), n = 200) + 25
plot.ts(x)
library(tseries)
adf.test(x)
acf2(x)
fit <- sarima(x, p = 2, q = 0, d = 0)
x<- arima.sim(model = list(order = c(2,0,0), ar = c(1.25,-0.75)), n = 200) + 25
plot.ts(x)
x<- arima.sim(model = list(order = c(1,0,0), ar = c(-0.75)), n = 200) + 25
plot.ts(x)
x<- arima.sim(model = list(order = c(1,0,0), ar = c(0.75)), n = 200) + 25
plot.ts(x)
x<- arima.sim(model = list(order = c(0,0,1), ma = c(0.75)), n = 200) + 25
plot.ts(x)
x<- arima.sim(model = list(order = c(0,0,0)), n = 200) + 25
plot.ts(x)
x<- arima.sim(model = list(order = c(0,1,0)), n = 200) + 25
plot.ts(x)
as.ts(bodyfat)
bf <- arima.sim(bodyfat)
bf <- arima.sim(bodyfat, n=20)
bf
plot(bf)
adf.test(bf)
acf(bf)
acf2(bf)
length(bodyfat)
shape(bodyfat)
bodyfat.summary()
dim(bodyfat)
library(forecast)
auto.arima(bf)
read.csv("C:/Users/Serina Brenner/Documents/school/spring 2018/PK/guess_the_series_1.csv")
guess <- read.csv("C:/Users/Serina Brenner/Documents/school/spring 2018/PK/guess_the_series_1.csv")
as.ts(guess)
plot(guess)
acf(guess)
auto.arima(guess)
libaray(astsa)
a <- arima.sim(model = list(order = c(1,1,0),ar=0.4),n=200)
plot.ts(cbind(a,diff(a)))
library(tseries)
adf.test(a)
adf.test(diff(a))
acf2(a)
acf2(diff(a))
sarima.for(a,p=1,d=1,q=0, n/ahead = 20)
sarima.for(a,p=1,d=1,q=0, n.ahead = 20)
pacf(diff(a))
pacf(a)
pacf(diff(a))
data(oil)
summary(oil)
plot.ts(oil)
head(oil)
oil
oil2
oiltrain <- window(oil, c(2002,1), c(2006,52))
oiltest  <- window(oil, c(2007,1), c(2007,52))
plot(oiltrain)
acf(oiltrain)
acf2(oiltrain)
acf2(diff(oiltrain))
auto.arima(oiltrain)
auto.arima(diff(oiltrain))
sarima.for(oiltrain, p=1, d=1, q=1, n.ahead= 52)
lines(oiltest)
data(globtemp)
gttrain <- window(globtemp, c(1880,1), c(2010,52))
plot(gttrain)
acf2(diff(gttrain))
auto.arima(gttrain)
sarima.for(gttrain, p=1,d=1,q=1, n.ahead=52)
lines(gttest)
gttest  <- window(globtemp, c(2011,1), c(2015,52))
lines(gttest)
sarima.for(gttrain, p=1,d=1,q=1, n.ahead=52)
lines(gttest)
lines(gttest)
sarima.for(oiltrain, p=1, d=1, q=1, n.ahead= 52)
lines(oiltest)
sarima.for(gttrain, p=1,d=1,q=1, n.ahead=52)
lines(gttest)
plot(gttest)
lines(gttest)
sarima.for(gttrain, p=1,d=1,q=1, n.ahead=52)
lines(gttest)
auto.arima(gttrain)
sarima.for(gttrain, p=1,d=1,q=1, n.ahead=52)
lines(gttest)
sarima.for(gttrain, p=1,d=1,q=1, n.ahead=15)
lines(gttest)
sarima.for(gttrain, p=1,d=1,q=1, n.ahead=10)
lines(gttest)
sarima.for(gttrain, p=1,d=1,q=1, n.ahead=5)
lines(gttest)
acf2(diff(gttrain))
gttrain <- window(globtemp, c(1880,1), c(2010,1))
gttest  <- window(globtemp, c(2011,1), c(2015,1))
acf2(diff(gttrain))
auto.arima(gttrain)
sarima.for(gttrain, p=1,d=1,q=1, n.ahead=5)
lines(gttest)
gttest  <- window(globtemp, c(2010,1), c(2015,1))
lines(gttest)
library(tidyr)
df <- read.csv(file="C:/Users/Serina Brenner/Documents/school/spring 2018/visualization/students/int.csv" header=TRUE, set=",")
df <- read.csv(file="C:/Users/Serina Brenner/Documents/school/spring 2018/visualization/students/int.csv", header=TRUE, set=",")
df <- read.csv(file="C:/Users/Serina Brenner/Documents/school/spring 2018/visualization/students/int.csv", header=TRUE)
df
df.head<()
df.head()
head(df)
data_long <- gather(df, Program, Percent, 'Business/ Mgmt.':'Undeclared', factor_key=TRUE)
data_long
df[2]
data_long <- gather(df, Program, Percent, df[2]:df[13], factor_key=TRUE)
df <- read.csv(file="C:/Users/Serina Brenner/Documents/school/spring 2018/visualization/students/int.csv", header=TRUE)
head(df)
data_long <- gather(df, Program, Percent, 'Business Mgmt.':'Undeclared', factor_key=TRUE)
df[2]
data_long
head(df)
data_long <- gather(df, Program, Percent, Business Mgmt.:Undeclared, factor_key=TRUE)
?gather
?reshape2
library(reshape2)
?cast
library(astsa)
wn_2 <- arima.sim(model = list(order = c(0,0,0)), n = 100, mean = 10, sd = 3)
ts.plot (wn_2, col="#aa0000")
wn <- arima.sim(model = list(order = c(0,0,0)), n = 100, mean = 10, sd = 3)
ts.plot (wn, col="#aa0000")
rw <- arima.sim(model = list(order = c(0,1,0)), n = 100)
ts.plot(rw)
ts.plot(rw, col="#aa0000")
library(astsa)
data(jj)
adf.test(jj)
plot.ts(jj)
adf.test(jj)
test(jj)
library(tseries)
adf.test(jj)
acf2(jj)
fit_1 <- sarima(jj,p=1,q=0,d=0)
fit_2 <- sarima(jj,p=2,q=0,d=0)
fit_3 <- sarima(jj,p=1,q=0,d=1)
fit_4 <- sarima(jj,p=3,q=0,d=0)
fit_1 <- sarima(jj,p=1,q=0,d=0)
data(jj)
plot.ts(jj)
adf.test(jj)
library(forecast)
auto.arima(jj)
fit_5 <- sarima(jj,p=0,q=1,d=0)
fit_1 <- sarima(jj,p=1,q=0,d=0)
data(jj)
fit_1
fit_2
fit_3
fit_4
fit_5
fit_1
fit_2
fit_3
fit_4
fit_5
plot.ts(jj)
sarima.for(jj,n.ahead=8,p=1,q=0,d=1)
sarima.for(jj,n.ahead=8,p=0,q=1,d=0)
sarima.for(jj,n.ahead=8,p=1,q=0,d=1)
data(gnp)
plot.ts(gnp)
adf.test(gnp)
acf2(gnp)
auto.arima(gnp)
fit_1 <- sarima(jj,p=1,q=0,d=0)   #AIC : 1.73   BIC : 0.79    pvalar1 : 0.00    pvalxmean : 0.04
fit_2 <- sarima(jj,p=2,q=0,d=0)   #AIC : 1.39   BIC : 0.48    pvalar2 : 0.58    pvalxmean : 0.19
fit_3 <- sarima(jj,p=1,q=0,d=1)   #AIC : 1.32   BIC : 0.38    pvalar1 : 0.00    pvalxmean : 0.05
fit_4 <- sarima(jj,p=3,q=0,d=0)   #AIC : 5.51   BIC : 4.54    pvalar3 : 0.37    pvalxmean : 0.00
fit_5 <- sarima(jj,p=2,q=2,d=1)   #AIC : 3.21   BIC : 2.27    pvalar1 : 0.00    pvalxmean : 0.00
fit_1
fit_1 <- sarima(gnp,p=1,q=0,d=0)   #AIC : 1.73   BIC : 0.79    pvalar1 : 0.00    pvalxmean : 0.04
fit_2 <- sarima(gnp,p=2,q=0,d=0)   #AIC : 1.39   BIC : 0.48    pvalar2 : 0.58    pvalxmean : 0.19
fit_3 <- sarima(gnp,p=1,q=0,d=1)   #AIC : 1.32   BIC : 0.38    pvalar1 : 0.00    pvalxmean : 0.05
fit_4 <- sarima(gnp,p=3,q=0,d=0)   #AIC : 5.51   BIC : 4.54    pvalar3 : 0.37    pvalxmean : 0.00
fit_5 <- sarima(gnp,p=2,q=2,d=1)   #AIC : 3.21   BIC : 2.27    pvalar1 : 0.00    pvalxmean : 0.00
fit_1
fit1 <- sarima(gnp,p=1,q=0,d=0)   #AIC : 1.73   BIC : 0.79    pvalar1 : 0.00    pvalxmean : 0.04
fit2 <- sarima(gnp,p=2,q=0,d=0)   #AIC : 1.39   BIC : 0.48    pvalar2 : 0.58    pvalxmean : 0.19
fit3 <- sarima(gnp,p=1,q=0,d=1)   #AIC : 1.32   BIC : 0.38    pvalar1 : 0.00    pvalxmean : 0.05
fit4 <- sarima(gnp,p=3,q=0,d=0)   #AIC : 5.51   BIC : 4.54    pvalar3 : 0.37    pvalxmean : 0.00
fit5 <- sarima(gnp,p=2,q=2,d=1)   #AIC : 3.21   BIC : 2.27    pvalar1 : 0.00    pvalxmean : 0.00
fit1
fit1 <- sarima(gnp,p=1,q=0,d=0)   #AIC : 1.73   BIC : 0.79    pvalar1 : 0.00    pvalxmean : 0.04
fit1
data(marathon)
data(rec)
plot.ts(rec)
plot.ts(log(rec,4))
plot.ts(rec)
plot.ts(diff(rec))
plot.ts(log(rec,12))
plot.ts(rec)
library(fma)
install.packages('fma')
library(fma)
data(advert)
advert
summary(advert)
ts.plot(advert)
ts.plot(advert, col="aabb33")
ts.plot(advert)
ts.plot(advert, col="#aabb33")
ts.plot(advert, col="#44bb33")
library(fma)
data(advert)
advert
summary(advert)
ts.plot(advert, col="#44bb33")
acf2(advert)
library(astsa)
library(tseries)
acf2(advert)
data(chicken)
ts.plot(chicken)
holt(chicken, exponential = TRUE)
x1 = holt(chicken, exponential = TRUE)
ts.plot(x1)
data(fma::chicken)
data(fma:chicken)
install.packages('fpp2')
library(fpp2)
data(a10)
ts.plot(a10)
x2 = holt(chicken, exponential = TRUE, seasonal = "additive")
ts.plot(x2)
ts.plot(x2)x2
x2
install.packages('Rserve')
library(Rserve)
Rserve()
##########Comparing Lexicons############
library(tm)
library(ggplot2)
library(tidytext)
library(gutenbergr)
library(dplyr)
library(tidyr)
clean_corpus <- function(cleaned_corpus){
cleaned_corpus <- tm_map(cleaned_corpus, removeWords, stopwords("english"))
cleaned_corpus <- tm_map(cleaned_corpus, stripWhitespace)
return(cleaned_corpus)
}
library(tm)
library(qdap)
library(tibble)
library(ggplot2)
library(RWeka)
library(wordcloud)
library(lubridate)
library(lexicon)
library(tidytext)
library(lubridate)
library(gutenbergr)
library(stringr)
library(dplyr)
library(radarchart)
bing_lex <- get_sentiments("bing")
bing_lex
gutenberg_metadata
install.packages('shiny')
install.packages('ggplot2')
install.packages('shinythemes')
library(shiny)
library(ggplot2)
library(shinythemes)
load(url("https://stat.duke.edu/~mc301/data/movies.Rdata"))
ui <- fluidPage(theme = shinytheme("superhero"),
# Sidebar layout with a input and output definitions
sidebarLayout(
# Inputs
sidebarPanel(
sliderInput("table", h3("Audience_Score"),
min = 0, max = 100, value = 50)
),
# Outputs
mainPanel(
plotOutput(outputId = "table")
)
)
)
server <- function(input, output) {
newdf <- movies[which(movies$audience_score == input$table),]
# Create scatterplot object the plotOutput function is expecting
output$table <- renderDataTable(newdf)
}
shinyApp(ui = ui, server = server)
runApp('school/spring 2018/PK/lesson_8_r/shiny_10.R')
runApp('school/spring 2018/PK/lesson_8_r/shiny_9.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
library(shiny); runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
library(shiny); runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
runApp('school/spring 2018/PK/lesson_8_r/lindttry.R')
library(wordcloud)
library(tm)
library(ggplot2)
library(SnowballC)
library(data.table)
library(stringr)
library(qdap)
library(tibble)
library(RWeka)
library(lubridate)
library(lexicon)
library(tidytext)
library(gutenbergr)
library(dplyr)
library(radarchart)
setwd("C:/Users/Serina Brenner/Documents/GitHub/Text-Analytics")
mysearch <- read.csv(file="search.csv", header=TRUE, sep=",")
mysearch$text <- iconv(mysearch$text, from = "UTF-8", to = "ASCII", sub = "")
mysearch_corp <- VCorpus(VectorSource(mysearch$text))
library(twitteR)
library(rtweet)
library(data.table)
library(stringr)
library(tidytext)
setwd("C:/Users/Serina Brenner/Documents/GitHub/Text-Analytics")
#-- o -- o -- o -- o -- o -- o -- o -- o -- o -- o -- o -- o -- o -- o -- o --
# read 2000 tweets and save to csv
#-- o -- o -- o -- o -- o -- o -- o -- o -- o -- o -- o -- o -- o -- o -- o --
# twitter keys
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
setup_twitter_oauth('ZbGmXn3PQ7iAE2Z0dEu7mfSMk', 'NesQtlEtVIUb6MCUCHaWRo8D0TFmL8LlJfibvwP1zFvf4OVago', '1309079071-uqqbxNGbk3k47GjYafbWguOUv25QhTlX8eb4UbR', 'aVJc8ov2vAiClaeWk4UYzbVXJfoir3KLWP67AOhsJkBu2')
# search and df to csv
mysearch <- searchTwitter("hawaiian pizza",n=2000)
mysearch.df <- twListToDF(mysearch)
write.csv(mysearch.df, file = "search.csv",row.names=FALSE)
# important columns:
#   text                    --> actual tweet
#   longitude/latitude      --> locations
#   favorited/favoriteCount --> fav info
